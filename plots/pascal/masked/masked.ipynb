{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seml.database as db_utils\n",
    "import torch\n",
    "\n",
    "from localized_smoothing.segmentation.eval import (\n",
    "        calc_certified_pixel_accuracy_naive,\n",
    "        calc_certified_ratios_naive,\n",
    "        calc_pixel_accuracy,\n",
    "        calc_mean_iou,\n",
    "        calc_certified_ratios_collective,\n",
    "        calc_certified_pixel_accuracy_center,\n",
    "        calc_certified_ratios_center,\n",
    "        calc_certified_pixel_accuracy_collective)\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from utils import load_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'cert_images_pascal_masked'\n",
    "\n",
    "\n",
    "jk_config = {\n",
    "    'username': 'your_username',\n",
    "    'password': 'your_password',\n",
    "    'host': 'host_ip',\n",
    "    'port': 27017,\n",
    "    'db_name': 'your_db_name'\n",
    "}\n",
    "\n",
    "col = db_utils.get_collection(collection, mongodb_config=jk_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_under_curve(x,\n",
    "                     y,\n",
    "                     pre=True):\n",
    "    if pre:\n",
    "        return np.diff(x) @ y[1:]\n",
    "    else:\n",
    "        return np.diff(x) @ y[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments(col, restrictions={}):\n",
    "    \n",
    "    restrictions['status'] = 'COMPLETED'\n",
    "\n",
    "    if col.count_documents(restrictions) == 0:\n",
    "        raise ValueError('No matches!')\n",
    "\n",
    "    exps = col.find(restrictions, {'result': 1, 'stats': 1, 'host': 1})\n",
    "    \n",
    "    return exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_dict_iid(exp, cert_type='argmax_holm', abstain=True, n_images=100, n_classes=21):\n",
    "    res = torch.load(exp['result']['cert_file'])\n",
    "    config = res.pop('config')\n",
    "    budgets = res['budgets']\n",
    "\n",
    "\n",
    "    results_dict = {\n",
    "        'std': config['distribution_params']['std_min'],\n",
    "        'grid_height': config['distribution_params']['grid_shape'][0],\n",
    "        'grid_width': config['distribution_params']['grid_shape'][1],\n",
    "        'n_samples_pred': config['sample_params']['n_samples_pred'],\n",
    "        'n_samples_cert': config['sample_params']['n_samples_cert'],\n",
    "    }\n",
    "\n",
    "    results_dict.update({\n",
    "        'accuracy': calc_pixel_accuracy(res, cert_type, False, abstain, n_images, n_classes),\n",
    "        'iou': calc_mean_iou(res, cert_type, False, abstain=abstain, n_images=n_images),\n",
    "        'budgets': budgets,\n",
    "        'certified_ratios': calc_certified_ratios_naive(res, cert_type, n_images, n_classes),\n",
    "        'certified_accuracies': calc_certified_pixel_accuracy_naive(res, cert_type, n_images, n_classes),\n",
    "        #'certified_ratios_center': calc_certified_ratios_center(res, n_pixels=(166*250)),\n",
    "        #'certified_accuracies_center': calc_certified_pixel_accuracy_center(res, n_pixels=(166*250), n_images=n_images),\n",
    "        'time': exp['stats']['real_time'],\n",
    "        'vram': exp['host']['gpus']['gpus'][0]['total_memory']\n",
    "    })\n",
    "\n",
    "    for metric, pre in product(['ratios', 'accuracies'], [True, False]):\n",
    "\n",
    "        results_dict[f'auc_{metric}_{\"pre\" if pre else \"post\"}'] = area_under_curve(\n",
    "            results_dict['budgets'],\n",
    "            results_dict[f'certified_{metric}'],\n",
    "            pre\n",
    "        )\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_dicts_center(exp, n_images=100, n_classes=21):\n",
    "    res = torch.load(exp['result']['cert_file'])\n",
    "    config = res.pop('config')\n",
    "    budgets = res['budgets']\n",
    "\n",
    "\n",
    "    results_dict = {\n",
    "        'std': config['distribution_params']['std_min'],\n",
    "        'grid_height': config['distribution_params']['grid_shape'][0],\n",
    "        'grid_width': config['distribution_params']['grid_shape'][1],\n",
    "        'n_samples_pred': config['sample_params']['n_samples_pred'],\n",
    "        'n_samples_cert': config['sample_params']['n_samples_cert'],\n",
    "    }\n",
    "\n",
    "    results_dict.update({\n",
    "        'iou': calc_mean_iou(res, 'center_bonferroni', True, abstain=False, n_images=n_images),\n",
    "        'budgets': budgets,\n",
    "        'certified_accuracies': calc_certified_pixel_accuracy_center(res, n_images=n_images, n_classes=n_classes),\n",
    "        'time': exp['stats']['real_time'],\n",
    "        'vram': exp['host']['gpus']['gpus'][0]['total_memory']\n",
    "    })\n",
    "\n",
    "    for metric, pre in product(['accuracies'], [True, False]):\n",
    "\n",
    "        results_dict[f'auc_{metric}_{\"pre\" if pre else \"post\"}'] = area_under_curve(\n",
    "            results_dict['budgets'],\n",
    "            results_dict[f'certified_{metric}'],\n",
    "            pre\n",
    "        )\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_dict_collective(exp, cert_type='argmax_holm', abstain=True, n_images=100, n_classes=21, store_accumulate_gradients=True):\n",
    "    \n",
    "    res = torch.load(exp['result']['cert_file'])\n",
    "    config = res.pop('config')\n",
    "    budgets = res['budgets']\n",
    "\n",
    "    results_dict = {\n",
    "        'std': config['distribution_params']['std_min'],\n",
    "        'std_max': config['distribution_params']['std_max'],\n",
    "        'grid_height': config['distribution_params']['grid_shape'][0],\n",
    "        'grid_width': config['distribution_params']['grid_shape'][1],\n",
    "        'n_samples_pred': config['sample_params']['n_samples_pred'],\n",
    "        'n_samples_cert': config['sample_params']['n_samples_cert'],\n",
    "    }\n",
    "\n",
    "    if store_accumulate_gradients:\n",
    "        results_dict['acc_grads'] = config['train_loading']['restrictions']['training_params']['accumulate_gradients']\n",
    "    results_dict.update({\n",
    "        'accuracy': calc_pixel_accuracy(res, cert_type, False, abstain, n_images, n_classes),\n",
    "        'iou': calc_mean_iou(res, cert_type, False, abstain=abstain, n_images=n_images),\n",
    "        'budgets': budgets,\n",
    "        'certified_ratios_all': calc_certified_ratios_collective(res, cert_type, True, False, n_images, n_classes),\n",
    "        'certified_ratios_correct': calc_certified_ratios_collective(res, cert_type, False, True, n_images, n_classes),\n",
    "        'certified_accuracies_all': calc_certified_pixel_accuracy_collective(res, cert_type, True, False, n_images, n_classes),\n",
    "        'certified_accuracies_correct': calc_certified_pixel_accuracy_collective(res, cert_type, False, True, n_images, n_classes),\n",
    "        'time': exp['stats']['real_time'],\n",
    "        'vram': exp['host']['gpus']['gpus'][0]['total_memory']\n",
    "    })\n",
    "\n",
    "    for metric, subset, pre in product(['ratios', 'accuracies'], ['all', 'correct'], [True, False]):\n",
    "\n",
    "        results_dict[f'auc_{metric}_{subset}_{\"pre\" if pre else \"post\"}'] = area_under_curve(\n",
    "            results_dict['budgets'],\n",
    "            results_dict[f'certified_{metric}_{subset}'],\n",
    "            pre\n",
    "        )\n",
    "\n",
    "    return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = get_experiments(col, {'config.distribution_params.mask_distance': 1, 'config.certification_params.base_certs': ['argmax_holm']})\n",
    "results_iid = load_results(get_results_dict_iid, exps, './data/pascal_masked_iid', overwrite=False)  # Set to True if you want to use your own results\n",
    "print(len(list(exps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = get_experiments(col, {'config.distribution_params.mask_distance': 1, 'config.certification_params.base_certs': ['argmax_holm']})\n",
    "results_collective = load_results(get_results_dict_collective, exps, './data/pascal_masked_collective', overwrite=False)  # Set to True if you want to use your own results\n",
    "print(len(list(exps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_center = get_experiments(col, {'config.distribution_params.mask_distance': 1, 'config.certification_params.base_certs': [],\n",
    "                                     'config.certification_params.naive_certs': ['center_independent', 'center_bonferroni']})\n",
    "results_center = load_results(get_result_dicts_center, exps_center, './data/pascal_masked_center', overwrite=False)  # Set to True if you want to use your own results\n",
    "print(len(list(exps_center)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_collective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results_collective['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dominated(ious, cert_accs):\n",
    "    iou_worse = ious[:, np.newaxis] < ious\n",
    "\n",
    "    cert_accs_worse = cert_accs[:, np.newaxis] < cert_accs\n",
    "\n",
    "    worse = iou_worse & cert_accs_worse\n",
    "\n",
    "    dominated = np.any(worse, axis=1)\n",
    "\n",
    "    return ious[~dominated], cert_accs[~dominated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(results_iid, results_center, results_collective, n_samples_iid, n_samples_center, n_samples_collective, std_min=None, pareto=True):\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    #plt.figure(facecolor='white')\n",
    "\n",
    "    pal = sns.color_palette('colorblind', 3)\n",
    "\n",
    "    ious_collective = results_collective['iou'].to_numpy()\n",
    "    if std_min is not None:\n",
    "        ious_collective = np.append(ious_collective, results_iid.loc[results_iid['std'] == std_min]['iou'].iloc[0])\n",
    "\n",
    "    aucs_collective = results_collective['auc_accuracies_correct_post'].to_numpy()\n",
    "    if std_min is not None:\n",
    "        aucs_collective = np.append(aucs_collective, results_iid.loc[results_iid['std'] == std_min]['auc_accuracies_post'].iloc[0])\n",
    "\n",
    "    if pareto:\n",
    "        ious_collective, aucs_collective = filter_dominated(ious_collective, aucs_collective)\n",
    "\n",
    "    plt.scatter(ious_collective, aucs_collective, label='Localized LP', marker='.', s=20, color=pal[0])\n",
    "\n",
    "    # center\n",
    "\n",
    "    results_center = results_center.loc[results_center['n_samples_pred'] == n_samples_center]\n",
    "\n",
    "    iid_center, auc_center = results_center['iou'].to_numpy(), results_center['auc_accuracies_post'].to_numpy()\n",
    "\n",
    "    if pareto:\n",
    "        iid_center, auc_center = filter_dominated(iid_center, auc_center)\n",
    "\n",
    "    plt.scatter(iid_center, auc_center, label='CenterSmooth', s=20, marker='x', color=pal[2])\n",
    "\n",
    "    # iid\n",
    "\n",
    "    results_iid = results_iid.loc[results_iid['n_samples_pred'] == n_samples_iid]\n",
    "\n",
    "    results_collective = results_collective.loc[results_collective['n_samples_pred'] == n_samples_collective]\n",
    "\n",
    "    iid_iou, auc_iou = results_iid['iou'].to_numpy(), results_iid['auc_accuracies_post'].to_numpy()\n",
    "\n",
    "    if pareto:\n",
    "        iid_iou, auc_iou = filter_dominated(iid_iou, auc_iou)\n",
    "\n",
    "    plt.scatter(iid_iou, auc_iou, label='SegCertify$^*$', s=20, marker='x', color=pal[1])\n",
    "\n",
    "    \n",
    "    plt.xlabel('mIOU')\n",
    "    plt.ylabel('Avg. cert. radius')\n",
    "    #plt.title(f'std_min = {std_min}')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 x 5, 820 samples\n",
    "std_mins = np.sort(list(set(results_collective['std'])))\n",
    "print(std_mins)\n",
    "\n",
    "plot(results_iid.loc[results_iid['grid_height'] != results_iid['grid_width']], \n",
    "     results_center.loc[results_center['grid_height'] != results_center['grid_width']], \n",
    "     results_collective.loc[results_collective['grid_height'] != results_collective['grid_width']], 820, 820, 820)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2, 820 samples\n",
    "\n",
    "std_mins = np.sort(list(set(results_collective['std'])))\n",
    "print(std_mins)\n",
    "\n",
    "plot(results_iid.loc[results_iid['grid_height'] == results_iid['grid_width']], \n",
    "     results_center.loc[results_center['grid_height'] == results_center['grid_width']], \n",
    "     results_collective.loc[results_collective['grid_height'] == results_collective['grid_width']], 820, 820, 820)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2, 3072 samples\n",
    "\n",
    "std_mins = np.sort(list(set(results_collective['std'])))\n",
    "print(std_mins)\n",
    "\n",
    "plot(results_iid.loc[results_collective['grid_height'] == results_collective['grid_width']], \n",
    "     results_center.loc[results_center['grid_height'] == results_center['grid_width']], \n",
    "     results_collective.loc[results_collective['grid_height'] == results_collective['grid_width']], 3072, 3072, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localized_smoothing_camera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85e2a4260fe07c9d68aa8d7545cb3541cf58dbbbb01d6436dd56af59bb09589b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
