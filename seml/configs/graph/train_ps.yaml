seml:
  executable: /nfs/homedirs/wollschl/staff/localized_smoothing/seml/scripts/graph/train.py
  conda_environment: localized-smoothing-cuda11
  project_root_dir: /nfs/homedirs/wollschl/staff/localized_smoothing/
  output_dir: /nfs/homedirs/wollschl/staff/localized_smoothing/experiments/slurm_out/train

slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 32G          # memory
    cpus-per-task: 6  # num cores
    time: 1-00:00     # max time, D-HH:MM
    partition: gpu_all

fixed:
  experiment_name: 'train'
  certify_test: False
  
  n_clusters: 1
  n_samples: 32
  max_p: 0.08
  max_m: 0.9

  training_params:
    batch_size: 32
    learning_rate_decay: 1
    learning_rate: 0.001
    weight_decay: 0.001

  model_data:
    name: 'GCNLarge'
    pretrained_name: 'None'
    model_params:
      n_hidden: 64
      p_dropout: 0.5

grid:
  seed:
    type: choice
    options:
      - 0
 
  dataset_name:
    type: choice
    options:
      - 'citeseer'
      - 'cora_ml'

zero_m:
  fixed: 
      min_p: 0.01
      min_m: 0.0

zero_p:
  fixed:
    min_m: 0.6
    min_p: 0.0