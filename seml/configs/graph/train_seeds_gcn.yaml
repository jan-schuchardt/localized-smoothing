seml:
  executable: /nfs/homedirs/wollschl/staff/localized_smoothing/seml/scripts/graph/train.py
  conda_environment: localized-smoothing
  project_root_dir: /nfs/homedirs/wollschl/staff/localized_smoothing/
  output_dir: /nfs/homedirs/wollschl/staff/localized_smoothing/experiments/slurm_out/train

slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 32G          # memory
    cpus-per-task: 6  # num cores
    time: 1-00:00     # max time, D-HH:MM
    partition: gpu_all

fixed:
  experiment_name: 'train'
  certify_test: False
  dataset_name: 'cora_ml'
  
  n_clusters: 1
  n_samples: 10
  max_p: 0.08
  max_m: 0.9
  min_p: 0.075
  min_m: 0.6
  training_params:
    batch_size: 10
    learning_rate_decay: 1
    learning_rate: 0.001
    weight_decay: 0.001

  model_data:
    name: 'GCNLarge'
    pretrained_name: 'None'
    model_params:
      n_hidden: 64
      p_dropout: 0.5

grid:
  seed:
    type: range
    min: 1
    max: 20
    step: 1
